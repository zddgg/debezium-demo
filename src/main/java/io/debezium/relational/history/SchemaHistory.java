package io.debezium.relational.history;

import io.debezium.config.Configuration;
import io.debezium.config.Field;
import io.debezium.pipeline.spi.OffsetContext;
import io.debezium.pipeline.spi.Offsets;
import io.debezium.pipeline.spi.Partition;
import io.debezium.relational.Tables;
import io.debezium.relational.ddl.DdlParser;
import org.apache.kafka.common.config.ConfigDef.Importance;
import org.apache.kafka.common.config.ConfigDef.Type;
import org.apache.kafka.common.config.ConfigDef.Width;

import java.time.Instant;
import java.util.Collections;
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;

public interface SchemaHistory {
    String CONFIGURATION_FIELD_PREFIX_STRING = "schema.history.internal.";
    Field NAME = Field.create("schema.history.internal.name").withDisplayName("Logical name for the database schema history").withType(Type.STRING).withWidth(Width.MEDIUM).withImportance(Importance.LOW).withDescription("The name used for the database schema history, perhaps differently by each implementation.").withValidation(Field::isOptional);
    Field SKIP_UNPARSEABLE_DDL_STATEMENTS = Field.create("schema.history.internal.skip.unparseable.ddl").withDisplayName("Skip DDL statements that cannot be parsed").withType(Type.BOOLEAN).withWidth(Width.SHORT).withImportance(Importance.LOW).withDescription("Controls the action Debezium will take when it meets a DDL statement in binlog, that it cannot parse.By default the connector will stop operating but by changing the setting it can ignore the statements which it cannot parse. If skipping is enabled then Debezium can miss metadata changes.").withDefault(false);
    Field STORE_ONLY_CAPTURED_TABLES_DDL = Field.create("schema.history.internal.store.only.captured.tables.ddl").withDisplayName("Store only DDL that modifies tables that are captured based on include/exclude lists").withType(Type.BOOLEAN).withWidth(Width.SHORT).withImportance(Importance.LOW).withDescription("Controls what DDL will Debezium store in database schema history. By default (false) Debezium will store all incoming DDL statements. If set to true, then only DDL that manipulates a captured table will be stored.").withDefault(false);
    Field STORE_ONLY_CAPTURED_DATABASES_DDL = Field.create("schema.history.internal.store.only.captured.databases.ddl").withDisplayName("Store only DDL that modifies tables of databases that are captured based on include/exclude lists").withType(Type.BOOLEAN).withWidth(Width.SHORT).withImportance(Importance.LOW).withDescription("Controls what DDL will Debezium store in database schema history. By default (true) only DDL that manipulates a table from captured schema/database will be stored. If set to false, then Debezium will store all incoming DDL statements.").withDefault(false);
    Field DDL_FILTER = Field.createInternal("schema.history.internal.ddl.filter").withDisplayName("DDL filter").withType(Type.STRING).withDefault("DROP TEMPORARY TABLE IF EXISTS .+ /\\* generated by server \\*/,INSERT INTO mysql.rds_heartbeat2\\(.*\\) values \\(.*\\) ON DUPLICATE KEY UPDATE value = .*,DELETE FROM mysql.rds_sysinfo.*,INSERT INTO mysql.rds_sysinfo\\(.*\\) values \\(.*\\),INSERT INTO mysql.rds_monitor\\(.*\\) values \\(.*\\) ON DUPLICATE KEY UPDATE value = .*,INSERT INTO mysql.rds_monitor\\(.*\\) values \\(.*\\),DELETE FROM mysql.rds_monitor.*,FLUSH RELAY LOGS.*,flush relay logs.*,SAVEPOINT .*,^\\s*#.*").withWidth(Width.LONG).withImportance(Importance.LOW).withDescription("A regular expression to filter out a subset of incoming DDL statements from processing and storing into schema history evolution.").withValidation(Field::isListOfRegex);
    Field INTERNAL_CONNECTOR_CLASS = Field.create("schema.history.internal.connector.class").withDisplayName("Debezium connector class").withType(Type.STRING).withWidth(Width.LONG).withImportance(Importance.HIGH).withDescription("The class of the Debezium database connector").withNoValidation();
    Field INTERNAL_CONNECTOR_ID = Field.create("schema.history.internal.connector.id").withDisplayName("Debezium connector identifier").withType(Type.STRING).withWidth(Width.SHORT).withImportance(Importance.HIGH).withDescription("The unique identifier of the Debezium connector").withNoValidation();
    Field INTERNAL_PREFER_DDL = Field.create("schema.history.internal.prefer.ddl").withDisplayName("Prefer DDL for schema recovery").withType(Type.BOOLEAN).withDefault(false).withWidth(Width.SHORT).withImportance(Importance.LOW).withDescription("Prefer DDL for schema recovery in case logical schema is present").withInvisibleRecommender().withNoValidation();

    void configure(Configuration var1, HistoryRecordComparator var2, SchemaHistoryListener var3, boolean var4);

    void start();

    void record(Map<String, ?> var1, Map<String, ?> var2, String var3, String var4) throws SchemaHistoryException;

    void record(Map<String, ?> var1, Map<String, ?> var2, String var3, String var4, String var5, TableChanges var6, Instant var7) throws SchemaHistoryException;

    /**
     * @deprecated
     */
    @Deprecated
    default void recover(Map<String, ?> source, Map<String, ?> position, Tables schema, DdlParser ddlParser) {
        this.recover(Collections.singletonMap(source, position), schema, ddlParser);
    }

    default void recover(Offsets<?, ?> offsets, Tables schema, DdlParser ddlParser) {
        Map<Map<String, ?>, Map<String, ?>> offsetMap = new HashMap();
        Iterator var5 = offsets.iterator();

        while (var5.hasNext()) {
            Map.Entry<? extends Partition, ? extends OffsetContext> entry = (Map.Entry) var5.next();
            if (entry.getValue() != null) {
                offsetMap.put(((Partition) entry.getKey()).getSourcePartition(), ((OffsetContext) entry.getValue()).getOffset());
            }
        }

        this.recover((Map) offsetMap, schema, ddlParser);
    }

    /**
     * @deprecated
     */
    @Deprecated
    void recover(Map<Map<String, ?>, Map<String, ?>> var1, Tables var2, DdlParser var3);

    void stop();

    boolean exists();

    boolean storageExists();

    void initializeStorage();
}
